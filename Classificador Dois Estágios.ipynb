{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final - Análise de Gols em uma Partida de Futebol\n",
    "Autor: Paulo Victor Lima |   Orientador : Sergio Lima Netto |    Universidade Federal do Rio de Janeiro - Escola Politécnica - Departamente de Engenharia Eletrônica e de Computação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Instalação das bibliotecas\n",
    "\n",
    "# !pip install pandas\n",
    "# # !pip install numpy\n",
    "# # !pip install seaborn\n",
    "# # !pip install matplotlib.pyplot\n",
    "# # !pip install plotly.express\n",
    "# # !pip install glob\n",
    "# !pip install yellowbrick\n",
    "# !pip install Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1408,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação das bibliotecas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import glob\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve\n",
    "import seaborn as sns\n",
    "from numpy import loadtxt\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from scipy.signal import medfilt\n",
    "from cmath import sqrt\n",
    "from numpy import argmax\n",
    "from cProfile import label\n",
    "from tkinter import OFF\n",
    "from sklearn import metrics\n",
    "from turtle import pos\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import RocCurveDisplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação Base de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classe set_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1409,
   "metadata": {},
   "outputs": [],
   "source": [
    "class set_config():\n",
    "    def __init__(self, match_generic_path, highlights_file_name):\n",
    "\n",
    "        #Carrega as features a serem consideradas\n",
    "        features_types = []\n",
    "        features_types = loadtxt(\"..\\config\\Features_Types.dat\", comments=\"#\", delimiter='\\n', dtype=str, ndmin=1)\n",
    "        self.features_types = features_types\n",
    "\n",
    "        ## Caminho padrão das partidas\n",
    "        self.match_generic_path = match_generic_path\n",
    "\n",
    "        # Nome Padrão arquivo \"Highlights\"\n",
    "        self.highlights_file_name = highlights_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set_config() para treinamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_config_treinamento():\n",
    "    \n",
    "        match_generic_path = '..\\\\database\\\\Treinamento\\\\**\\\\'\n",
    "\n",
    "        highlights_file_name = 'highlights.csv'\n",
    "        \n",
    "        return set_config(match_generic_path, highlights_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set_config() para testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_config_teste():\n",
    "    \n",
    "        match_generic_path = '..\\\\database\\\\Teste\\\\**\\\\'\n",
    "\n",
    "        highlights_file_name = 'highlights.csv'\n",
    "        \n",
    "        return set_config(match_generic_path, highlights_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set_config() para todas as partidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_config_Aux():\n",
    "    \n",
    "        match_generic_path = '..\\\\database\\\\Teste_e_Treinamento\\\\**\\\\'\n",
    "\n",
    "        highlights_file_name = 'highlights.csv'\n",
    "        \n",
    "        return set_config(match_generic_path, highlights_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_feature_group_paths():\n",
    "    grupo1 = \"..\\config\\Grupos\\Grupo1.dat\"\n",
    "    grupo2 = \"..\\config\\Grupos\\Grupo2.dat\"\n",
    "    grupo3 = \"..\\config\\Grupos\\Grupo3.dat\"\n",
    "    grupo4 = \"..\\config\\Grupos\\Grupo4.dat\"\n",
    "    grupo5 = \"..\\config\\Grupos\\Grupo5.dat\"\n",
    "    grupo6 = \"..\\config\\Grupos\\Grupo6.dat\"\n",
    "    grupo7 = \"..\\config\\Grupos\\Grupo7.dat\"\n",
    "    grupo8 = \"..\\config\\Grupos\\Grupo8.dat\"\n",
    "    grupo9 = \"..\\config\\Grupos\\Grupo9.dat\"\n",
    "\n",
    "    # feature_group_paths = [grupo1,grupo2,grupo3,grupo4,grupo5,grupo6,grupo7,grupo8,grupo9]\n",
    "    feature_group_paths = [grupo8]\n",
    "\n",
    "    return feature_group_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura Base de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição das Funções de leitura da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "\n",
    "\n",
    "counter=0\n",
    "\n",
    "def import_moments_classifictaion(match, len, highlights_file_name):\n",
    "    global counter\n",
    "    \n",
    "    #Caminho para os arquivos de features\n",
    "    match_by_feature_path = match + highlights_file_name\n",
    "\n",
    "    #Data frame com todos os intervalos de highligths de uma partida\n",
    "    highlights_file =  pd.DataFrame()\n",
    "\n",
    "    #nome das colunas do frame de highlights\n",
    "    colnames=['first_frame','last_frame', 'classification'] \n",
    "\n",
    "    #Data Frame com todos os highlights de uma partida\n",
    "    highlights_file = pd.read_csv(match_by_feature_path, names=colnames, index_col=None, sep =',', header=None)\n",
    "\n",
    "    #Data frame com os intervalos de highligths de uma partida\n",
    "    highlights_of_match = pd.DataFrame(list(range(1,len)), columns=['classification_perigo'], index=list(range(1,len)))\n",
    "\n",
    "    highlights_of_match['classification_perigo'] = np.nan\n",
    "    highlights_of_match['classification_gol'] = highlights_of_match['classification_perigo']\n",
    "    highlights_of_match['frame_id'] = list(range(counter+1,counter+len))\n",
    "\n",
    "    counter+=len    \n",
    "    \n",
    "    for index,row in highlights_file.iterrows():\n",
    "        first_frame = int(row['first_frame']) if int(row['first_frame']) != ' ' else 0\n",
    "        last_frame = int(row['last_frame']) if row['last_frame'] != ' ' else int(row['first_frame'])\n",
    "        classification_perigo = 'Perigo' if (row['classification'] == ' Gol' or row['classification'] == ' Perigo' or row['classification'] == ' Muito Perigo' ) else 'Normal'\n",
    "        classification_gol = 'Gol' if row['classification'] == ' Gol' else 'Não Gol'\n",
    "\n",
    "\n",
    "        highlights_of_match.loc[first_frame:last_frame, ['classification_perigo','classification_gol']] = [classification_perigo,classification_gol]\n",
    "        \n",
    "    return highlights_of_match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_database (set_config):\n",
    "\n",
    "    from numpy import loadtxt\n",
    "\n",
    "    #Carrega as features a serem consideradas\n",
    "    features_types = []\n",
    "    features_types = loadtxt(\"..\\config\\Features_Types.dat\", comments=\"#\", delimiter='\\n', dtype=str, ndmin=1)\n",
    "\n",
    "    ## Caminho padrão das partidas\n",
    "    match_generic_path = set_config.match_generic_path\n",
    "\n",
    "    #Lista de partidas existentes na base\n",
    "    all_matches = glob.glob(match_generic_path, recursive = False)\n",
    "\n",
    "    ## Data Frame com todos os momementos de todas as partidas\n",
    "    all_moments = pd.DataFrame()\n",
    "    ## Array de Data Frames com todos os Data Frames das partidas\n",
    "    all_moments_array = []\n",
    "\n",
    "    for match in all_matches:\n",
    "        print(match)\n",
    "\n",
    "        #Data frame com todos os momentos de uma partida\n",
    "        moments_of_match=  pd.DataFrame()\n",
    "\n",
    "        for feature in features_types:\n",
    "\n",
    "            #Caminho para os arquivos de features\n",
    "            match_by_feature_path = match + feature\n",
    "\n",
    "            #Data Frame com todos os momentos de uma partida de uma feature especifica\n",
    "            moments_of_match[feature] = pd.read_csv(match_by_feature_path, index_col=None, sep ='\\n', thousands=r\".\", header=None)\n",
    "        \n",
    "        #Preenche a coluna 'Match' com a partida\n",
    "        moments_of_match['Match'] = [match_by_feature_path.split('\\\\')[-2] for _ in range(len(moments_of_match[feature]))]\n",
    "\n",
    "        moments_of_match[['Classification_Perigo','Classification_Gol','Frame_ID']] = import_moments_classifictaion(match, len(moments_of_match[feature]), set_config.highlights_file_name)  \n",
    "\n",
    "        moments_of_match.dropna(axis=0, how='any',inplace=True)\n",
    "\n",
    "        #Adiciona ao array de Data Frames o Data Frame gerado para a partida\n",
    "        all_moments_array.append(moments_of_match)\n",
    "\n",
    "    all_moments = pd.concat(all_moments_array,  sort=False, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "    all_moments.to_csv( set_config.match_generic_path.split('\\\\')[-3] + \"moments.csv\", index=False, sep=';')\n",
    "    return all_moments\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão Previsores e Classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previsores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictors(all_moments, columns_names):\n",
    "    return all_moments[columns_names].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_perigo(all_moments):\n",
    "    return all_moments['Classification_Perigo'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_gol(all_moments):\n",
    "    return all_moments['Classification_Gol'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Second_Stage_Df(features_in_group, predictors_teste, classes_teste_perigo, predictions_perigo_after_filter, classes_teste_gol):\n",
    "        df_predictor_teste = pd.DataFrame(predictors_teste)\n",
    "        df_classes_teste_perigo = pd.DataFrame(classes_teste_perigo)\n",
    "        df_predictions_perigo_after_filter = pd.DataFrame(np.array(predictions_perigo_after_filter))\n",
    "        df_classes_teste_gol = pd.DataFrame(classes_teste_gol)\n",
    "\n",
    "        df_second_stage_intermediary = pd.concat([df_predictor_teste, df_classes_teste_perigo, df_predictions_perigo_after_filter, df_classes_teste_gol], axis=1, ignore_index=True)\n",
    "\n",
    "        column_names = ['Classification_Teste_Perigo', 'Prediction_Teste_Perigo', 'Classification_Gol']\n",
    "        column_names = np.append(features_in_group, column_names)\n",
    "        df_second_stage_intermediary.columns = column_names\n",
    "\n",
    "        #Filtra Apenas os casos que foram classificados Corretamente no primeiro estágio\n",
    "        df_second_stage_intermediary = df_second_stage_intermediary.loc[(df_second_stage_intermediary['Classification_Teste_Perigo'] == df_second_stage_intermediary['Prediction_Teste_Perigo'])]\n",
    "        #Filtra Apenas os casos que foram classificados como Perigo no primeiro estágio\n",
    "        return df_second_stage_intermediary.loc[(df_second_stage_intermediary['Classification_Teste_Perigo'] == 'Perigo')]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teste_gol(N,predictorsTreinamento, classesTreinamento, predictorsTeste,threshold):\n",
    "        ##Cria o Random Forest e realiza o teste\n",
    "        random_forest = RandomForestClassifier(n_estimators=N,criterion='gini',random_state=0, class_weight=\"balanced\")\n",
    "        random_forest.fit(predictorsTreinamento, classesTreinamento)\n",
    "\n",
    "        # predicted_proba = random_forest.predict_proba(predictorsTeste)\n",
    "\n",
    "        # df_teste = pd.DataFrame(columns=['Gol', 'Não Gol'])\n",
    "\n",
    "        # df_teste['Gol'] = predicted_proba[:,0]\n",
    "        # df_teste['Não Gol'] = predicted_proba[:,1]\n",
    "\n",
    "        # print(threshold)\n",
    "        # predicted = (random_forest.predict_proba(predictorsTeste)[:,0] >= threshold).astype(int)\n",
    "\n",
    "        # df_teste['Previsto'] = ['GOL' if x==1 else 'Não GOL' for x in medfilt(predicted,kernel_size=1)]\n",
    "        \n",
    "        # df_teste.to_csv( \"..\\\\..\\\\Resultados Modelo\\\\Teste.csv\", index=False, sep=';')\n",
    "\n",
    "        \n",
    "        predicted = (random_forest.predict_proba(predictorsTeste)[:,0] >= threshold).astype(int)\n",
    "        # predicted = (random_forest.predict_proba(predictorsTeste)[:,0]).astype(int)\n",
    "        return predicted\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teste_perigo(N,predictorsTreinamento, classesTreinamento, predictorsTeste,threshold):\n",
    "        ##Cria o Random Forest e realiza o teste\n",
    "        random_forest = RandomForestClassifier(n_estimators=N,criterion='gini',random_state=0, class_weight=\"balanced\")\n",
    "        random_forest.fit(predictorsTreinamento, classesTreinamento)\n",
    "\n",
    "        # predicted_proba = random_forest.predict_proba(predictorsTeste)\n",
    "\n",
    "        # df_teste = pd.DataFrame(columns=['Normal', 'Perigo'])\n",
    "\n",
    "        # df_teste['Normal'] = predicted_proba[:,0]\n",
    "        # df_teste['Perigo'] = predicted_proba[:,1]\n",
    "\n",
    "        # print(threshold)\n",
    "        # predicted = (random_forest.predict_proba(predictorsTeste)[:,1] >= threshold).astype(int)\n",
    "\n",
    "        # df_teste['Previsto'] = ['Perigo' if x==1 else 'Normal' for x in medfilt(predicted,kernel_size=1)]\n",
    "        \n",
    "        # df_teste.to_csv( \"..\\\\..\\\\Resultados Modelo\\\\Teste.csv\", index=False, sep=';')\n",
    "\n",
    "        predicted = (random_forest.predict_proba(predictorsTeste)[:,1] >= threshold).astype(int)\n",
    "        # predicted = (random_forest.predict_proba(predictorsTeste)[:,0]).astype(int)\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva Roc e Filtro de Mediana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro de Mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter(predictions, classificacaoPositiva, classificacaoNegativa,WindowWidth):\n",
    "    #Aplica o Filtro de Mediana\n",
    "\n",
    "        return [classificacaoPositiva if x==1 else classificacaoNegativa for x in medfilt(predictions,kernel_size=WindowWidth)]\n",
    "        # return [classificacaoPositiva if x==1 else classificacaoNegativa for x in medfilt(binary_preditction)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter_binary(predictions, WindowWidth):\n",
    "    #Aplica o Filtro de Mediana\n",
    "    return medfilt(predictions, kernel_size=WindowWidth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva Roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_plot_gol(N,predictorsTreinamento, classesTreinamento, predictorsTeste, classes_teste, classificacaoPositiva):\n",
    "\n",
    "        ##Cria o Random Forest e realiza o teste\n",
    "        random_forest = RandomForestClassifier(n_estimators=N,criterion='gini',random_state=0, class_weight=\"balanced\")\n",
    "        random_forest.fit(predictorsTreinamento, classesTreinamento)\n",
    "\n",
    "        predictions = random_forest.predict_proba(predictorsTeste)[:,0]\n",
    "        fpr, tpr, threshold = metrics.roc_curve(classes_teste, predictions,pos_label=classificacaoPositiva)\n",
    "        auc = round(metrics.roc_auc_score(classes_teste, predictions), 4)\n",
    "\n",
    "        major_ticks_x = np.arange(0, 1.01, 0.1)\n",
    "        major_ticks_y = np.arange(0, 1.01, 0.05)\n",
    "        minor_ticks = np.arange(0, 1, 0.05)\n",
    "        plt.plot(threshold,tpr,label=\"Taxa de Verdadeiro Positivo\")\n",
    "        plt.plot(threshold,fpr,label=\"Taxa de Falso Positivo\")\n",
    "        # plt.plot(fpr,tpr,label=\"Curva Roc - Random Forest (AUC = \" + str(auc)+\")\")\n",
    "        plt.xticks(major_ticks_x)\n",
    "        plt.yticks(major_ticks_y)\n",
    "        plt.xlabel('False Positive Rate (Positive Label: Perigo)')\n",
    "        plt.ylabel('True Positive Rate (Positive Label: Perigo)')\n",
    "        plt.xlabel('Limiar')\n",
    "        plt.ylabel('Taxa')\n",
    "        plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]\n",
    "        plt.xlim([0.0,1.0])\n",
    "        plt.ylim([0.0,1.0])\n",
    "        plt.legend()\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_plot_perigo(N,predictorsTreinamento, classesTreinamento, predictorsTeste, classes_teste, classificacaoPositiva):\n",
    "\n",
    "        ##Cria o Random Forest e realiza o teste\n",
    "        random_forest = RandomForestClassifier(n_estimators=N,criterion='gini',random_state=0, class_weight=\"balanced\")\n",
    "        random_forest.fit(predictorsTreinamento, classesTreinamento)\n",
    "\n",
    "        predictions = random_forest.predict_proba(predictorsTeste)[:,1]\n",
    "        fpr, tpr, threshold = metrics.roc_curve(classes_teste, predictions,pos_label=classificacaoPositiva)\n",
    "        auc = round(metrics.roc_auc_score(classes_teste, predictions), 4)\n",
    "\n",
    "        major_ticks_x = np.arange(0, 1.0, 0.1)\n",
    "        major_ticks_y = np.arange(0, 1.0, 0.05)\n",
    "        minor_ticks = np.arange(0, 1, 0.05)\n",
    "        plt.plot(threshold,tpr,label=\"Taxa de Verdadeiro Positivo\")\n",
    "        plt.plot(threshold,fpr,label=\"Taxa de Falso Positivo\")\n",
    "        # plt.plot(fpr,tpr,label=\"Curva Roc - Random Forest (AUC = \" + str(auc)+\")\")\n",
    "        plt.xticks(major_ticks_x)\n",
    "        plt.yticks(major_ticks_y)\n",
    "        plt.xlabel('False Positive Rate (Positive Label: Perigo)')\n",
    "        plt.ylabel('True Positive Rate (Positive Label: Perigo)')\n",
    "        plt.xlabel('Limiar')\n",
    "        plt.ylabel('Taxa')\n",
    "        plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]\n",
    "        plt.xlim([0.0,1.0])\n",
    "        plt.ylim([0,1.0])\n",
    "        plt.legend()\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1426,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_roc_curve_plot(N,predictorsTreinamento, classesTreinamento, predictorsTeste, classes_teste, classificacaoPositiva, threshold):\n",
    "        ##Cria o Random Forest e realiza o teste\n",
    "        random_forest = RandomForestClassifier(n_estimators=N,criterion='gini',random_state=0, class_weight=\"balanced\")\n",
    "        random_forest.fit(predictorsTreinamento, classesTreinamento)\n",
    "\n",
    "        predictions = random_forest.predict_proba(predictorsTeste)[:,0]\n",
    "        fpr, tpr, threshold_second_stage = metrics.roc_curve(classes_teste, predictions,pos_label=classificacaoPositiva)\n",
    "        # auc = round(metrics.roc_auc_score(classes_teste, predictions), 4)\n",
    "\n",
    "        major_ticks_x = np.arange(0, 1, 0.1)\n",
    "        major_ticks_y = np.arange(0, 1, 0.05)\n",
    "        minor_ticks = np.arange(0, 1, 0.05)\n",
    "        # plt.plot(fpr,tpr,label=\"Limiar Primeiro Estágio=\"+str(round(threshold, 2)))\n",
    "        plt.plot(threshold_second_stage,tpr,label=\"Taxa de Verdadeiro Positivo\"+str(round(threshold, 2)))\n",
    "        # plt.plot(threshold_second_stage,fpr,label=\"Taxa de Falso Positivo\"+str(round(threshold, 2)))\n",
    "        plt.xticks(major_ticks_x)\n",
    "        plt.yticks(major_ticks_y)\n",
    "        # plt.xlabel('Taxa Falso Positivo (Classificação Positiva: Gol)')\n",
    "        # plt.ylabel('Taxa Verdadeiro Positivo (Classificação Positiva: Gol)')\n",
    "        plt.xlabel('Limiar')\n",
    "        plt.ylabel('Taxa de Verdadeiro Positivo')\n",
    "        plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]\n",
    "        plt.xlim([0.0,1.0])\n",
    "        plt.ylim([0,1.0])\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Results_Two_Stages_roc_curve(df_results, features_in_group, N, group_name, predictors_treinamento, classes_treinamento_perigo, classes_treinamento_gol, predictors_teste, classes_teste_perigo, classes_teste_gol):\n",
    "        \n",
    "        for threshold in np.arange(0.0,0.54,0.05):\n",
    "                print(threshold)\n",
    "\n",
    "                #######################################Primeiro Estágio####################################\n",
    "                predictions_perigo = teste_perigo(N, predictors_treinamento, classes_treinamento_perigo, predictors_teste,threshold)\n",
    "                predictions_perigo_after_filter =  median_filter(predictions_perigo, 'Perigo', 'Normal')\n",
    "                df_second_stage = get_Second_Stage_Df(features_in_group, predictors_teste, classes_teste_perigo, predictions_perigo_after_filter, classes_teste_gol)\n",
    "                \n",
    "\n",
    "        #         #######################################Segundo Estágio####################################\n",
    "                df_second_stage = get_Second_Stage_Df(features_in_group, predictors_teste, classes_teste_perigo, predictions_perigo_after_filter, classes_teste_gol)\n",
    "\n",
    "\n",
    "                # Separa Preditores e Classificadores da base de teste\n",
    "                predictors_teste_second_stage = get_predictors(df_second_stage,features_in_group)\n",
    "                classes_teste_gol_second_stage = get_classes_gol(df_second_stage)\n",
    "\n",
    "                multiple_roc_curve_plot(N, predictors_treinamento, classes_treinamento_gol, predictors_teste_second_stage,classes_teste_gol_second_stage,'Gol',threshold)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_goal_rate_curve_plot(N,predictorsTreinamento, classesTreinamento, predictorsTeste, classes_teste, classificacaoPositiva, threshold):\n",
    "        ##Cria o Random Forest e realiza o teste\n",
    "        random_forest = RandomForestClassifier(n_estimators=N,criterion='gini',random_state=0, class_weight=\"balanced\")\n",
    "        random_forest.fit(predictorsTreinamento, classesTreinamento)\n",
    "        \n",
    "\n",
    "        predictions = random_forest.predict_proba(predictorsTeste)[:,0]\n",
    "        predictions_gol = (predictions >= 0.5).astype(int)\n",
    "        predictions_gol_after_filter =  median_filter(predictions_gol, 'Gol', 'Não Gol')\n",
    "\n",
    "\n",
    "        #Verifica quantos gols foram previstos no primeiro estágio\n",
    "        tp, fn, fp, tn = confusion_matrix(classes_teste, predictions_gol_after_filter).ravel()\n",
    "        first_stage_predicted_goals = tp+fn\n",
    "        first_stage_predicted_not_goals = tn+fp\n",
    "\n",
    "        fpr, tpr, threshold_second_stage = metrics.roc_curve(classes_teste, predictions,pos_label=classificacaoPositiva)\n",
    "        \n",
    "        predicted_goals_rate = (first_stage_predicted_goals * tpr)/4217\n",
    "        false_predicted_goals_rate = (first_stage_predicted_not_goals * fpr)/18614\n",
    "\n",
    "        # print(predicted_goals_rate)\n",
    "\n",
    "        major_ticks_x = np.arange(0, 1.01, 0.1)\n",
    "        major_ticks_y = np.arange(0, 1.01, 0.05)\n",
    "        minor_ticks = np.arange(0, 1, 0.05)\n",
    "        # plt.plot(threshold_second_stage,predicted_goals_rate,label=\"Assertividade de Gols (Threshold Primeiro Estágio=\"+str(round(threshold, 2))+\")\")\n",
    "        # plt.plot(threshold_second_stage,false_predicted_goals_rate,label=\"Total de Falso Positivos (Threshold Primeiro Estágio=\"+str(round(threshold, 2))+\")\")\n",
    "        # plt.plot(false_predicted_goals_rate,predicted_goals_rate,label=\"Threshold Primeiro Estágio=\"+str(round(threshold, 2)))\n",
    "        plt.plot(threshold_second_stage,false_predicted_goals_rate,label=\"Threshold Primeiro Estágio=\"+str(round(threshold, 2)))\n",
    "        plt.xticks(major_ticks_x)\n",
    "        plt.yticks(major_ticks_y)\n",
    "        plt.ylabel('Falso Positivo Total')\n",
    "        plt.xlabel('Limiar')\n",
    "        # plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]\n",
    "        plt.xlim([0.0,1.0])\n",
    "        plt.ylim([0.0,1.0])\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1429,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Two_Stages_total_goal_positive_rate(df_results, features_in_group, N, group_name, predictors_treinamento, classes_treinamento_perigo, classes_treinamento_gol, predictors_teste, classes_teste_perigo, classes_teste_gol):\n",
    "        \n",
    "        for threshold in np.arange(0.0,0.54,0.05):\n",
    "        # for threshold in np.arange(0.15,0.19,0.05):\n",
    "                print(threshold)\n",
    "\n",
    "                #######################################Primeiro Estágio####################################\n",
    "                predictions_perigo = teste_perigo(N, predictors_treinamento, classes_treinamento_perigo, predictors_teste,threshold)\n",
    "                predictions_perigo_after_filter =  median_filter(predictions_perigo, 'Perigo', 'Normal')\n",
    "                df_second_stage = get_Second_Stage_Df(features_in_group, predictors_teste, classes_teste_perigo, predictions_perigo_after_filter, classes_teste_gol)\n",
    "                \n",
    "\n",
    "        #         #######################################Segundo Estágio####################################\n",
    "                df_second_stage = get_Second_Stage_Df(features_in_group, predictors_teste, classes_teste_perigo, predictions_perigo_after_filter, classes_teste_gol)\n",
    "\n",
    "\n",
    "                # Separa Preditores e Classificadores da base de teste\n",
    "                predictors_teste_second_stage = get_predictors(df_second_stage,features_in_group)\n",
    "                classes_teste_gol_second_stage = get_classes_gol(df_second_stage)\n",
    "\n",
    "                multiple_goal_rate_curve_plot(N, predictors_treinamento, classes_treinamento_gol, predictors_teste_second_stage,classes_teste_gol_second_stage,'Gol',threshold)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_plot_gol_multiples_window_width(N,predictorsTreinamento, classesTreinamento, predictorsTeste, classes_teste, classificacaoPositiva):\n",
    "\n",
    "    for window_width in np.arange(0,501,100):\n",
    "        print(window_width)\n",
    "        ##Cria o Random Forest e realiza o teste\n",
    "        random_forest = RandomForestClassifier(n_estimators=N,criterion='gini',random_state=0, class_weight=\"balanced\")\n",
    "        random_forest.fit(predictorsTreinamento, classesTreinamento)\n",
    "\n",
    "        predictions = random_forest.predict_proba(predictorsTeste)[:,0]\n",
    "        predictions_after_mediand_filter = median_filter_binary(predictions, window_width+1)\n",
    "\n",
    "        fpr, tpr, threshold = metrics.roc_curve(classes_teste, predictions_after_mediand_filter,pos_label=classificacaoPositiva)\n",
    "        auc = round(metrics.roc_auc_score(classes_teste, predictions_after_mediand_filter), 4)\n",
    "\n",
    "        major_ticks_x = np.arange(0, 1.01, 0.1)\n",
    "        major_ticks_y = np.arange(0, 1.01, 0.05)\n",
    "        minor_ticks = np.arange(0, 1, 0.05)\n",
    "        # plt.plot(threshold,tpr,label=\"Taxa de Verdadeiro Positivo\")\n",
    "        # plt.plot(threshold,fpr,label=\"Taxa de Falso Positivo\")\n",
    "        plt.plot(fpr,tpr,label=\"Curva Roc - Random Forest (Tamanho da Janela = \" + str(window_width+1)+\")\")\n",
    "        plt.xticks(major_ticks_x)\n",
    "        plt.yticks(major_ticks_y)\n",
    "        plt.xlabel('False Positive Rate (Positive Label: Gol)')\n",
    "        plt.ylabel('True Positive Rate (Positive Label: Gol)')\n",
    "        # plt.xlabel('Limiar')\n",
    "        # plt.ylabel('Taxa')\n",
    "        plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]\n",
    "        plt.xlim([-0.01,1.01])\n",
    "        plt.ylim([-0.01,1.01])\n",
    "        plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_plot_perigo_multiples_window_width(N,predictorsTreinamento, classesTreinamento, predictorsTeste, classes_teste, classificacaoPositiva):\n",
    "\n",
    "    for window_width in np.arange(0,201,50):\n",
    "        print(window_width)\n",
    "        ##Cria o Random Forest e realiza o teste\n",
    "        random_forest = RandomForestClassifier(n_estimators=N,criterion='gini',random_state=0, class_weight=\"balanced\")\n",
    "        random_forest.fit(predictorsTreinamento, classesTreinamento)\n",
    "\n",
    "        predictions = random_forest.predict_proba(predictorsTeste)[:,1]\n",
    "        predictions_after_mediand_filter = median_filter_binary(predictions, window_width+1)\n",
    "\n",
    "        fpr, tpr, threshold = metrics.roc_curve(classes_teste, predictions_after_mediand_filter,pos_label=classificacaoPositiva)\n",
    "        auc = round(metrics.roc_auc_score(classes_teste, predictions_after_mediand_filter), 4)\n",
    "\n",
    "        major_ticks_x = np.arange(0, 1.01, 0.1)\n",
    "        major_ticks_y = np.arange(0, 1.01, 0.05)\n",
    "        minor_ticks = np.arange(0, 1, 0.05)\n",
    "        # plt.plot(threshold,tpr,label=\"Taxa de Verdadeiro Positivo\")\n",
    "        # plt.plot(threshold,fpr,label=\"Taxa de Falso Positivo\")\n",
    "        plt.plot(fpr,tpr,label=\"Curva Roc - Random Forest (Tamanho da Janela = \" + str(window_width+1)+\")\")\n",
    "        plt.xticks(major_ticks_x)\n",
    "        plt.yticks(major_ticks_y)\n",
    "        plt.xlabel('False Positive Rate (Positive Label: Perigo)')\n",
    "        plt.ylabel('True Positive Rate (Positive Label: Perigo)')\n",
    "        # plt.xlabel('Limiar')\n",
    "        # plt.ylabel('Taxa')\n",
    "        plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]\n",
    "        plt.xlim([0.0,1.0])\n",
    "        plt.ylim([0.0,1.0])\n",
    "        plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1432,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_roc_curve_plot_median_filter(N,predictorsTreinamento, classesTreinamento, predictorsTeste, classes_teste, classificacaoPositiva, window_width):\n",
    "        ##Cria o Random Forest e realiza o teste\n",
    "        random_forest = RandomForestClassifier(n_estimators=N,criterion='gini',random_state=0, class_weight=\"balanced\")\n",
    "        random_forest.fit(predictorsTreinamento, classesTreinamento)\n",
    "\n",
    "        predictions = random_forest.predict_proba(predictorsTeste)[:,0]\n",
    "        predictions_after_mediand_filter = median_filter_binary(predictions, window_width+1)\n",
    "\n",
    "        fpr, tpr, threshold_second_stage = metrics.roc_curve(classes_teste, predictions,pos_label=classificacaoPositiva)\n",
    "        # auc = round(metrics.roc_auc_score(classes_teste, predictions), 4)\n",
    "\n",
    "        major_ticks_x = np.arange(0, 1, 0.1)\n",
    "        major_ticks_y = np.arange(0, 1, 0.05)\n",
    "        minor_ticks = np.arange(0, 1, 0.05)\n",
    "        plt.plot(fpr,tpr,label=\"Limiar Primeiro Estágio=\"+str(round(window_width, 2)))\n",
    "        # plt.plot(threshold_second_stage,tpr,label=\"Taxa de Verdadeiro Positivo\"+str(round(threshold, 2)))\n",
    "        # plt.plot(threshold_second_stage,fpr,label=\"Taxa de Falso Positivo\"+str(round(threshold, 2)))\n",
    "        plt.xticks(major_ticks_x)\n",
    "        plt.yticks(major_ticks_y)\n",
    "        plt.xlabel('False Positive Rate (Positive Label: Gol)')\n",
    "        plt.ylabel('True Positive Rate (Positive Label: Gol)')\n",
    "        # plt.xlabel('Limiar')\n",
    "        # plt.ylabel('Taxa de Verdadeiro Positivo')\n",
    "        plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]\n",
    "        plt.xlim([0.0,1.0])\n",
    "        plt.ylim([0,1.0])\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Results_Two_Stages_roc_curve_with_median_filter(df_results, features_in_group, N, group_name, predictors_treinamento, classes_treinamento_perigo, classes_treinamento_gol, predictors_teste, classes_teste_perigo, classes_teste_gol):\n",
    "        \n",
    "    for window_width in np.arange(0,201,50):\n",
    "                print(window_width)\n",
    "\n",
    "                #######################################Primeiro Estágio####################################\n",
    "                predictions_perigo = teste_perigo(N, predictors_treinamento, classes_treinamento_perigo, predictors_teste,0.15)\n",
    "                predictions_perigo_after_filter =  median_filter(predictions_perigo, 'Perigo', 'Normal',window_width+1)\n",
    "                df_second_stage = get_Second_Stage_Df(features_in_group, predictors_teste, classes_teste_perigo, predictions_perigo_after_filter, classes_teste_gol)\n",
    "                \n",
    "\n",
    "        #         #######################################Segundo Estágio####################################\n",
    "                df_second_stage = get_Second_Stage_Df(features_in_group, predictors_teste, classes_teste_perigo, predictions_perigo_after_filter, classes_teste_gol)\n",
    "\n",
    "\n",
    "                # Separa Preditores e Classificadores da base de teste\n",
    "                predictors_teste_second_stage = get_predictors(df_second_stage,features_in_group)\n",
    "                classes_teste_gol_second_stage = get_classes_gol(df_second_stage)\n",
    "\n",
    "                multiple_roc_curve_plot_median_filter(N, predictors_treinamento, classes_treinamento_gol, predictors_teste_second_stage,classes_teste_gol_second_stage,'Gol',window_width)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geração dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Results_One_stage(df_results, N, group_name, predictors_treinamento, classes_treinamento_gol, predictors_teste, classes_teste_gol):\n",
    "        start_time = time.time()\n",
    "        predictions = teste_gol(N, predictors_treinamento, classes_treinamento_gol, predictors_teste,0.15)\n",
    "        duration_first_stage = round(time.time() - start_time, 2)\n",
    "        # roc_curve_plot_gol(N,predictors_treinamento, classes_treinamento_gol,predictors_teste, classes_teste_gol,'Gol')\n",
    "        # roc_curve_plot_gol_multiples_window_width(N,predictors_treinamento, classes_treinamento_gol,predictors_teste, classes_teste_gol,'Gol')\n",
    "\n",
    "        predictions_after_filter =  median_filter(predictions, 'Gol', 'Não Gol',201)\n",
    "\n",
    "        df_teste = pd.DataFrame(predictions_after_filter)\n",
    "        df_teste.to_csv( \"..\\\\..\\\\Resultados Modelo\\\\teste.csv\", index=False, sep=';')\n",
    "\n",
    "        result = confusion_matrix(classes_teste_gol,predictions_after_filter).ravel()       \n",
    "\n",
    "        result = np.append(result, duration_first_stage)\n",
    "        result = np.append(accuracy_score(classes_teste_gol, predictions_after_filter), result)\n",
    "        result = np.append(result, N)\n",
    "        result = np.append(result, group_name)\n",
    "        df_result = pd.DataFrame(result).transpose()\n",
    "        df_result.columns = [\"Assertividade Total\", \"Verdadeiro Positivo\",\"Falso Negativo\",\"Falso Positivo\",\"Verdadeiro Negativo\",\"Tempo(s)\", \"N\", \"Grupo\"]\n",
    "        return pd.concat([df_results, df_result], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Results_Two_Stages(df_results, features_in_group, N, group_name, predictors_treinamento, classes_treinamento_perigo, classes_treinamento_gol, predictors_teste, classes_teste_perigo, classes_teste_gol):\n",
    "        \n",
    "        # get_Results_Two_Stages_roc_curve(df_results, features_in_group, N, group_name, predictors_treinamento, classes_treinamento_perigo, classes_treinamento_gol, predictors_teste, classes_teste_perigo, classes_teste_gol)\n",
    "        # get_Two_Stages_total_goal_positive_rate(df_results, features_in_group, N, group_name, predictors_treinamento, classes_treinamento_perigo, classes_treinamento_gol, predictors_teste, classes_teste_perigo, classes_teste_gol)\n",
    "\n",
    "        # get_Results_Two_Stages_roc_curve_with_median_filter(df_results, features_in_group, N, group_name, predictors_treinamento, classes_treinamento_perigo, classes_treinamento_gol, predictors_teste, classes_teste_perigo, classes_teste_gol)\n",
    "       \n",
    "        ######################################Primeiro Estágio####################################\n",
    "        start_time = time.time()\n",
    "        predictions_perigo = teste_perigo(N, predictors_treinamento, classes_treinamento_perigo, predictors_teste,0.15)\n",
    "        duration_first_stage = round(time.time() - start_time, 2)\n",
    "        # roc_curve_plot_perigo(N, predictors_treinamento, classes_treinamento_perigo, predictors_teste,classes_teste_perigo,'Perigo')\n",
    "        # roc_curve_plot_perigo_multiples_window_width(N, predictors_treinamento, classes_treinamento_perigo, predictors_teste,classes_teste_perigo,'Perigo')\n",
    "\n",
    "\n",
    "        predictions_perigo_after_filter =  median_filter(predictions_perigo, 'Perigo', 'Normal',51)\n",
    "    \n",
    "        result_first_stage = confusion_matrix(classes_teste_perigo, predictions_perigo_after_filter).ravel()\n",
    "        accuracy_first_stage = accuracy_score(classes_teste_perigo, predictions_perigo_after_filter)\n",
    "\n",
    "        result = np.append(accuracy_first_stage, result_first_stage)\n",
    "        result = np.append(result, duration_first_stage)\n",
    "\n",
    "\n",
    "        #######################################Segundo Estágio####################################\n",
    "        df_second_stage = get_Second_Stage_Df(features_in_group, predictors_teste, classes_teste_perigo, predictions_perigo_after_filter, classes_teste_gol)\n",
    "\n",
    "        # Separa Preditores e Classificadores da base de teste\n",
    "        predictors_teste_second_stage = get_predictors(df_second_stage,features_in_group)\n",
    "        classes_teste_gol_second_stage = get_classes_gol(df_second_stage)\n",
    "\n",
    "        start_time = time.time()\n",
    "        predictions_gol = teste_gol(N, predictors_treinamento, classes_treinamento_gol, predictors_teste_second_stage,0.08)\n",
    "        duration_second_stage = round(time.time() - start_time, 2)\n",
    "        # roc_curve_plot_gol(N, predictors_treinamento, classes_treinamento_gol, predictors_teste_second_stage,classes_teste_gol_second_stage,'Gol')\n",
    "        # roc_curve_plot_gol_multiples_window_width(N, predictors_treinamento, classes_treinamento_gol, predictors_teste_second_stage,classes_teste_gol_second_stage,'Gol')\n",
    "        \n",
    "        predictions_gol_after_filter =  median_filter(predictions_gol, 'Gol', 'Não Gol',101)\n",
    "        \n",
    "        accuracy_second_stage = accuracy_score(classes_teste_gol_second_stage, predictions_gol_after_filter)\n",
    "        result_second_stage = confusion_matrix(classes_teste_gol_second_stage, predictions_gol_after_filter).ravel()\n",
    "\n",
    "        result = np.append(result, accuracy_second_stage)\n",
    "        result = np.append(result, result_second_stage)\n",
    "        result = np.append(result, duration_second_stage)\n",
    "\n",
    "        ######################################Resultados Dois Estágios ##########################\n",
    "\n",
    "        result = np.append(result, N)\n",
    "        result = np.append(result, group_name)\n",
    "        df_result = pd.DataFrame(result).transpose()\n",
    "        column_names = [\"Assertividade Total - Primeiro Estagio\", \"Verdadeiro Negativo - Primeiro Estagio\",\"Falso Positivo - Primeiro Estagio\", \"Falso Negativo - Primeiro Estagio\", \"Verdadeiro Positivo - Primeiro Estagio\",\"Tempo(s) - Primeiro Estagio\",\"Assertividade Total - Segundo Estagio\", \"Verdadeiro Positivo - Segundo Estagio\",\"Falso Negativo - Segundo Estagio\",\"Falso Positivo - Segundo Estagio\",\"Verdadeiro Negativo - Segundo Estagio\",\"Tempo(s) - Segundo Estagio\", \"N\", \"Grupo\"]\n",
    "        df_result.columns = column_names\n",
    "        return pd.concat([df_results, df_result], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Results(features_in_group, group_name, moments_treinamento, moments_test):\n",
    "    ############################################################################################\n",
    "\n",
    "    # Separa Preditores e Classificadores da base de treinamento\n",
    "    predictors_treinamento = get_predictors(moments_treinamento, features_in_group)\n",
    "    classes_treinamento_perigo = get_classes_perigo(moments_treinamento)\n",
    "    classes_treinamento_gol = get_classes_gol(moments_treinamento)\n",
    "\n",
    "    # Separa Preditores e Classificadores da base de teste\n",
    "    predictors_teste = get_predictors(moments_test,features_in_group)\n",
    "    classes_teste_perigo = get_classes_perigo(moments_test)\n",
    "    classes_teste_gol = get_classes_gol(moments_test)\n",
    "\n",
    "    # print('Primeiro Estágio')\n",
    "    # Verifica_Importancia(predictors_treinamento, classes_treinamento_perigo)\n",
    "    # print('Segundo Estágio')\n",
    "    # Verifica_Importancia(predictors_treinamento, classes_treinamento_gol)\n",
    "\n",
    " \n",
    "\n",
    "    df_results_one_stage = pd.DataFrame()\n",
    "    df_results_two_stages = pd.DataFrame()\n",
    "    # for N in range(1,101,3):\n",
    "    for N in range(40,41):\n",
    "\n",
    "\n",
    "        print('Valor de N: %d ' % (N))\n",
    "        df_results_one_stage = get_Results_One_stage(df_results_one_stage, N, group_name, predictors_treinamento, classes_treinamento_gol, predictors_teste, classes_teste_gol)\n",
    "        # df_results_two_stages = get_Results_Two_Stages(df_results_two_stages, features_in_group, N, group_name, predictors_treinamento, classes_treinamento_perigo, classes_treinamento_gol, predictors_teste, classes_teste_perigo, classes_teste_gol)\n",
    "\n",
    "\n",
    "    df_results_one_stage = df_results_one_stage[[\"Assertividade Total\", \"Verdadeiro Positivo\",\"Verdadeiro Negativo\",\"Falso Positivo\",\"Falso Negativo\",\"Tempo(s)\",  \"N\", \"Grupo\"]]\n",
    "    # df_results_two_stages = df_results_two_stages[[\"Assertividade Total - Primeiro Estagio\", \"Verdadeiro Positivo - Primeiro Estagio\",\"Verdadeiro Negativo - Primeiro Estagio\",\"Falso Positivo - Primeiro Estagio\",\"Falso Negativo - Primeiro Estagio\",\"Tempo(s) - Primeiro Estagio\",\"Assertividade Total - Segundo Estagio\", \"Verdadeiro Positivo - Segundo Estagio\",\"Verdadeiro Negativo - Segundo Estagio\",\"Falso Positivo - Segundo Estagio\",\"Falso Negativo - Segundo Estagio\",\"Tempo(s) - Segundo Estagio\", \"N\", \"Grupo\"]]\n",
    "    return [df_results_one_stage, df_results_two_stages]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grupo8\n",
      "Valor de N: 40 \n"
     ]
    }
   ],
   "source": [
    "# Configurações Gerais de Treinamento\n",
    "set_config_treinamento = set_config_treinamento()\n",
    "\n",
    "# Configurações Gerais de Teste\n",
    "set_config_teste = set_config_teste()\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "# # Importa a base de dados\n",
    "# all_moments_treinamento = pd.DataFrame()\n",
    "# all_moments_treinamento = import_database(set_config_treinamento)\n",
    "\n",
    "# # Importa a base de dados\n",
    "# all_moments_teste = pd.DataFrame()\n",
    "# all_moments_teste = import_database(set_config_teste)\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "# Caminhos dos Arquivos de Grupo de Atributo\n",
    "feature_group_paths = set_feature_group_paths()\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "\n",
    "final_result_one_stage = pd.DataFrame()\n",
    "final_result_two_stage = pd.DataFrame()\n",
    "for feature_group_path in feature_group_paths:\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    group_name = feature_group_path.split('\\\\')[-1].replace(\".dat\", \"\")\n",
    "    print(group_name)\n",
    "    \n",
    "    features_in_group = loadtxt(feature_group_path, comments=\"#\", delimiter='\\n', dtype=str, ndmin=1)\n",
    "    \n",
    "####################################### GERAR CSV DE RESULTADOS de Perigo ################################\n",
    "\n",
    "    [group_result_one_stage, group_result_two_stages] = get_Results(features_in_group, group_name, all_moments_treinamento, all_moments_teste)\n",
    "\n",
    "    final_result_one_stage = pd.concat([final_result_one_stage, group_result_one_stage], axis=0, ignore_index=True)\n",
    "    # final_result_two_stage = pd.concat([final_result_two_stage, group_result_two_stages], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "# final_result_one_stage.to_csv( \"..\\\\..\\\\Resultados Modelo\\\\RESULTADO-FINAL-UM-ESTAGIO-Median-Filter.csv\", index=False, sep=';')\n",
    "# final_result_two_stage.to_csv( \"..\\\\..\\\\Resultados Modelo\\\\RESULTADO-FINAL-DOIS-ESTAGIOS-Median-Filter.csv\", index=False, sep=';', decimal=',',float_format='%.3f')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_result_two_stage.to_csv( \"..\\\\..\\\\Resultados Modelo\\\\RESULTADO-FINAL-DOIS-ESTAGIOS-v2-gini.csv\", index=False, sep=';', decimal=',',float_format='%.3f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_result_one_stage.to_csv( \"..\\\\..\\\\Resultados Modelo\\\\RESULTADO-FINAL-UM-ESTAGIO.csv\", index=False, sep=';')\n",
    "# final_result_two_stage.to_csv( \"..\\\\..\\\\Resultados Modelo\\\\RESULTADO-FINAL-DOIS-ESTAGIOS.csv\", index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análises Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Verifica_Importancia(predictors_treinamento, classes_treinamento):\n",
    "\n",
    "#     ##############Verificar importancia das features######################\n",
    "#     from cProfile import label\n",
    "\n",
    "\n",
    "#     random_forest = RandomForestClassifier(n_estimators=100,criterion='gini',random_state=0)\n",
    "#     random_forest.fit(predictors_treinamento, classes_treinamento)\n",
    "\n",
    "#     importances = random_forest.feature_importances_\n",
    "#     std = np.std([tree.feature_importances_ for tree in random_forest.estimators_], axis=0)\n",
    "\n",
    "#     forest_importances = pd.Series(importances, index= ['Atributo 1','Atributo 2','Atributo 3','Atributo 4','Atributo 5','Atributo 6','Atributo 7','Atributo 8','Atributo 9','Atributo 10','Atributo 11','Atributo 12','Atributo 13','Atributo 14','Atributo 15','Atributo 16','Atributo 17','Atributo 18','Atributo 19'])\n",
    "\n",
    "\n",
    "#     fig, ax = plt.subplots()\n",
    "#     forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "#     ax.set_title(\"Importâncias dos Atributos usando MDI\")\n",
    "#     ax.set_ylabel(\"Redução Média de Impureza (MDI)\")\n",
    "#     fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Verifica_Importancia(predictors_treinamento, classes_treinamento_perigo, classes_treinamento_gol):\n",
    "\n",
    "#     ##############Verificar importancia das features Primeiro Estágio ######################\n",
    "#     from cProfile import label\n",
    "\n",
    "\n",
    "#     random_forest_first_stage = RandomForestClassifier(n_estimators=100,criterion='gini',random_state=0)\n",
    "#     random_forest_first_stage.fit(predictors_treinamento, classes_treinamento_perigo)\n",
    "\n",
    "#     importances_first_stage = random_forest_first_stage.feature_importances_\n",
    "#     std_first_stage = np.std([tree.feature_importances_ for tree in random_forest_first_stage.estimators_], axis=0)\n",
    "\n",
    "#     forest_importances_first_stage = pd.Series(importances_first_stage, index= ['Atributo 1','Atributo 2','Atributo 3','Atributo 4','Atributo 5','Atributo 6','Atributo 7','Atributo 8','Atributo 9','Atributo 10','Atributo 11','Atributo 12','Atributo 13','Atributo 14','Atributo 15','Atributo 16','Atributo 17','Atributo 18','Atributo 19'])\n",
    "\n",
    "\n",
    "#     fig, ax = plt.subplots()\n",
    "#     forest_importances_first_stage.plot.bar(yerr=std_first_stage, ax=ax)\n",
    "#     ax.set_title(\"Importâncias dos Atributos Primeiro Estágio usando MDI\")\n",
    "#     ax.set_ylabel(\"Redução Média de Impureza (MDI)\")\n",
    "#     fig.tight_layout()\n",
    "\n",
    "\n",
    "#     ##############Verificar importancia das features Segundo Estágio ######################\n",
    "#     from cProfile import label\n",
    "\n",
    "\n",
    "#     random_forest_second_stage = RandomForestClassifier(n_estimators=100,criterion='gini',random_state=0)\n",
    "#     random_forest_second_stage.fit(predictors_treinamento, classes_treinamento_gol)\n",
    "\n",
    "#     importances_second_stage = random_forest_second_stage.feature_importances_\n",
    "#     std_second_stage = np.std([tree.feature_importances_ for tree in random_forest_second_stage.estimators_], axis=0)\n",
    "\n",
    "#     forest_importances_second_stage = pd.Series(importances_second_stage, index= ['Atributo 1','Atributo 2','Atributo 3','Atributo 4','Atributo 5','Atributo 6','Atributo 7','Atributo 8','Atributo 9','Atributo 10','Atributo 11','Atributo 12','Atributo 13','Atributo 14','Atributo 15','Atributo 16','Atributo 17','Atributo 18','Atributo 19'])\n",
    "\n",
    "\n",
    "#     fig, ax = plt.subplots()\n",
    "#     forest_importances_second_stage.plot.bar(yerr=std_second_stage, ax=ax)\n",
    "#     ax.set_title(\"Importâncias dos Atributos Segundo Estágio usando MDI\")\n",
    "#     ax.set_ylabel(\"Redução Média de Impureza (MDI)\")\n",
    "#     fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Configurações Gerais de Treinamento\n",
    "# set_config_treinamento = set_config_Aux()\n",
    "\n",
    "# all_moments = import_database(set_config_treinamento)\n",
    "# sns.set(rc={'figure.figsize':(10.2,8.27)})\n",
    "# fig = sns.countplot(y=\"Classification\", hue=\"Match\", data = all_moments, palette=\"tab10\")\n",
    "\n",
    "# fig.set_xlabel(\"Quantidade\")\n",
    "# fig.set_ylabel(\"Classificação\")\n",
    "\n",
    "# plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "# fig = sns.countplot(y=\"Classification\", data = all_moments)\n",
    "# fig.set_xlabel(\"Quantidade\")\n",
    "# fig.set_ylabel(\"Classificação\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1444,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 734.4x595.44 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# entropia_direto = [[3017, 513], [1200, 18085]]# sns.heatmap(entropia_direto, annot=True, cmap='Reds', cbar=False, fmt='d')\n",
    "# # #####################################################################\n",
    "# Gini_direto = [[3003, 509], [1214, 18089]]# sns.heatmap(Gini_direto, annot=True, cmap='Reds', cbar=False, fmt='d')\n",
    "\n",
    "# #####################################################################\n",
    "# entropia_primeiro = [[2964, 474], [1253, 18124]]# sns.heatmap(entropia_primeiro, annot=True, cmap='Reds', cbar=False, fmt='d')\n",
    "\n",
    "# entropia_segundo = [[18083, 8], [41, 2956]]# sns.heatmap(entropia_segundo, annot=True, cmap='Reds', cbar=False, fmt='d')\n",
    "# ########################################################################\n",
    "# gini_primeiro = [[2948, 468], [1269, 18130]]# sns.heatmap(gini_primeiro, annot=True, cmap='Reds', cbar=False, fmt='d')\n",
    "\n",
    "gini_segundo = [[4217, 1517], [0, 5583]]\n",
    "sns.heatmap(gini_segundo, annot=True, cmap='Reds', cbar=False, fmt='d', xticklabels=['Positivo', 'Negativo'], yticklabels=['Positivo', 'Negativo'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52cdd3298a24792fb27a8d65377901584744076590a00194d66ccf79dc821d36"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
