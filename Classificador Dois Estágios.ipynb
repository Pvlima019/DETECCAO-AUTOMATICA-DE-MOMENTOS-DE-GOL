{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final - Análise de Gols em uma Partida de Futebol\n",
    "Autor: Paulo Victor Lima |   Orientador : Sergio Lima Netto |    Universidade Federal do Rio de Janeiro - Escola Politécnica - Departamente de Engenharia Eletrônica e de Computação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Instalação das bibliotecas\n",
    "\n",
    "# !pip install pandas\n",
    "# # !pip install numpy\n",
    "# # !pip install seaborn\n",
    "# # !pip install matplotlib.pyplot\n",
    "# # !pip install plotly.express\n",
    "# # !pip install glob\n",
    "# !pip install yellowbrick\n",
    "# !pip install Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação das bibliotecas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import glob\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve\n",
    "import seaborn as sns\n",
    "from numpy import loadtxt\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from scipy.signal import medfilt\n",
    "from cmath import sqrt\n",
    "from numpy import argmax\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação Base de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classe set_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "class set_config():\n",
    "    def __init__(self, match_generic_path, highlights_file_name):\n",
    "\n",
    "        #Carrega as features a serem consideradas\n",
    "        features_types = []\n",
    "        features_types = loadtxt(\"..\\config\\Features_Types.dat\", comments=\"#\", delimiter='\\n', dtype=str, ndmin=1)\n",
    "        self.features_types = features_types\n",
    "\n",
    "        ## Caminho padrão das partidas\n",
    "        self.match_generic_path = match_generic_path\n",
    "\n",
    "        # Nome Padrão arquivo \"Highlights\"\n",
    "        self.highlights_file_name = highlights_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set_config() para treinamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_config_treinamento():\n",
    "    \n",
    "        match_generic_path = '..\\\\database\\\\Treinamento\\\\**\\\\'\n",
    "\n",
    "        highlights_file_name = 'highlights.csv'\n",
    "        \n",
    "        return set_config(match_generic_path, highlights_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set_config() para testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_config_teste():\n",
    "    \n",
    "        match_generic_path = '..\\\\database\\\\Teste\\\\**\\\\'\n",
    "\n",
    "        highlights_file_name = 'highlights.csv'\n",
    "        \n",
    "        return set_config(match_generic_path, highlights_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set_config() para todas as partidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_config_Aux():\n",
    "    \n",
    "        match_generic_path = '..\\\\database\\\\Teste_e_Treinamento\\\\**\\\\'\n",
    "\n",
    "        highlights_file_name = 'highlights.csv'\n",
    "        \n",
    "        return set_config(match_generic_path, highlights_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_feature_group_paths():\n",
    "    grupo1 = \"..\\config\\Grupos\\Grupo1.dat\"\n",
    "    grupo2 = \"..\\config\\Grupos\\Grupo2.dat\"\n",
    "    grupo3 = \"..\\config\\Grupos\\Grupo3.dat\"\n",
    "    grupo4 = \"..\\config\\Grupos\\Grupo4.dat\"\n",
    "    grupo5 = \"..\\config\\Grupos\\Grupo5.dat\"\n",
    "    grupo6 = \"..\\config\\Grupos\\Grupo6.dat\"\n",
    "    grupo7 = \"..\\config\\Grupos\\Grupo7.dat\"\n",
    "    grupo8 = \"..\\config\\Grupos\\Grupo8.dat\"\n",
    "    grupo9 = \"..\\config\\Grupos\\Grupo9.dat\"\n",
    "\n",
    "    # feature_group_paths = [grupo1,grupo2,grupo3,grupo4,grupo5,grupo6,grupo7,grupo8,grupo9]\n",
    "    feature_group_paths = [grupo1]\n",
    "\n",
    "    return feature_group_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura Base de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição das Funções de leitura da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "\n",
    "\n",
    "counter=0\n",
    "\n",
    "def import_moments_classifictaion(match, len, highlights_file_name):\n",
    "    global counter\n",
    "    \n",
    "    #Caminho para os arquivos de features\n",
    "    match_by_feature_path = match + highlights_file_name\n",
    "\n",
    "    #Data frame com todos os intervalos de highligths de uma partida\n",
    "    highlights_file =  pd.DataFrame()\n",
    "\n",
    "    #nome das colunas do frame de highlights\n",
    "    colnames=['first_frame','last_frame', 'classification'] \n",
    "\n",
    "    #Data Frame com todos os highlights de uma partida\n",
    "    highlights_file = pd.read_csv(match_by_feature_path, names=colnames, index_col=None, sep =',', header=None)\n",
    "\n",
    "    #Data frame com os intervalos de highligths de uma partida\n",
    "    highlights_of_match = pd.DataFrame(list(range(1,len)), columns=['classification_perigo'], index=list(range(1,len)))\n",
    "\n",
    "    highlights_of_match['classification_perigo'] = np.nan\n",
    "    highlights_of_match['classification_gol'] = highlights_of_match['classification_perigo']\n",
    "    highlights_of_match['frame_id'] = list(range(counter+1,counter+len))\n",
    "\n",
    "    counter+=len    \n",
    "    \n",
    "    for index,row in highlights_file.iterrows():\n",
    "        first_frame = int(row['first_frame']) if int(row['first_frame']) != ' ' else 0\n",
    "        last_frame = int(row['last_frame']) if row['last_frame'] != ' ' else int(row['first_frame'])\n",
    "        classification_perigo = 'Perigo' if (row['classification'] == ' Gol' or row['classification'] == ' Perigo' or row['classification'] == ' Muito Perigo' ) else 'Normal'\n",
    "        classification_gol = 'Gol' if row['classification'] == ' Gol' else 'Não Gol'\n",
    "\n",
    "\n",
    "        highlights_of_match.loc[first_frame:last_frame, ['classification_perigo','classification_gol']] = [classification_perigo,classification_gol]\n",
    "        \n",
    "    return highlights_of_match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "import this\n",
    "\n",
    "\n",
    "def import_database (set_config):\n",
    "\n",
    "    from numpy import loadtxt\n",
    "\n",
    "    #Carrega as features a serem consideradas\n",
    "    features_types = []\n",
    "    features_types = loadtxt(\"..\\config\\Features_Types.dat\", comments=\"#\", delimiter='\\n', dtype=str, ndmin=1)\n",
    "\n",
    "    ## Caminho padrão das partidas\n",
    "    match_generic_path = set_config.match_generic_path\n",
    "\n",
    "    #Lista de partidas existentes na base\n",
    "    all_matches = glob.glob(match_generic_path, recursive = False)\n",
    "\n",
    "    ## Data Frame com todos os momementos de todas as partidas\n",
    "    all_moments = pd.DataFrame()\n",
    "    ## Array de Data Frames com todos os Data Frames das partidas\n",
    "    all_moments_array = []\n",
    "\n",
    "    for match in all_matches:\n",
    "        print(match)\n",
    "\n",
    "        #Data frame com todos os momentos de uma partida\n",
    "        moments_of_match=  pd.DataFrame()\n",
    "\n",
    "        for feature in features_types:\n",
    "\n",
    "            #Caminho para os arquivos de features\n",
    "            match_by_feature_path = match + feature\n",
    "\n",
    "            #Data Frame com todos os momentos de uma partida de uma feature especifica\n",
    "            moments_of_match[feature] = pd.read_csv(match_by_feature_path, index_col=None, sep ='\\n', thousands=r\".\", header=None)\n",
    "        \n",
    "        #Preenche a coluna 'Match' com a partida\n",
    "        moments_of_match['Match'] = [match_by_feature_path.split('\\\\')[-2] for _ in range(len(moments_of_match[feature]))]\n",
    "\n",
    "        moments_of_match[['Classification_Perigo','Classification_Gol','Frame_ID']] = import_moments_classifictaion(match, len(moments_of_match[feature]), set_config.highlights_file_name)  \n",
    "\n",
    "        moments_of_match.dropna(axis=0, how='any',inplace=True)\n",
    "\n",
    "        #Adiciona ao array de Data Frames o Data Frame gerado para a partida\n",
    "        all_moments_array.append(moments_of_match)\n",
    "\n",
    "    all_moments = pd.concat(all_moments_array,  sort=False, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "    all_moments.to_csv( set_config.match_generic_path.split('\\\\')[-3] + \"moments.csv\", index=False, sep=';')\n",
    "    return all_moments\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão Previsores e Classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previsores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictors(all_moments, columns_names):\n",
    "    return all_moments[columns_names].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_perigo(all_moments):\n",
    "    return all_moments['Classification_Perigo'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_gol(all_moments):\n",
    "    return all_moments['Classification_Gol'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teste(N,predictorsTreinamento, classesTreinamento, predictorsTeste,threshold):\n",
    "        ##Cria o Random Forest e realiza o teste\n",
    "        random_forest = RandomForestClassifier(n_estimators=N,criterion='entropy',random_state=0, class_weight=\"balanced\")\n",
    "        random_forest.fit(predictorsTreinamento, classesTreinamento)\n",
    "\n",
    "        # predicted = (random_forest.predict_proba(predictorsTeste)[:,1] >= threshold).astype(int)\n",
    "        predicted = (random_forest.predict_proba(predictorsTeste)[:,1]).astype(int)\n",
    "        return predicted\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def teste(N,predictorsTreinamento, classesTreinamento, predictorsTeste,threshold):\n",
    "#         ##Cria o Random Forest e realiza o teste\n",
    "#         random_forest = RandomForestClassifier(n_estimators=N,criterion='entropy',random_state=0, class_weight=\"balanced\")\n",
    "#         random_forest.fit(predictorsTreinamento, classesTreinamento)\n",
    "\n",
    "#         # return random_forest.predict(predictorsTeste)\n",
    "\n",
    "#         predicted = (random_forest.predict_proba(predictorsTeste)[:,1] >= threshold).astype(int)\n",
    "#         # predicted = (random_forest.predict_proba(predictorsTeste)).astype(int)\n",
    "#         # return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cProfile import label\n",
    "from turtle import pos\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "def roc_curve_plot(N,predictorsTreinamento, classesTreinamento, predictorsTeste, classes_teste, classificacaoPositiva):\n",
    "        ##Cria o Random Forest e realiza o teste\n",
    "        random_forest = RandomForestClassifier(n_estimators=N,criterion='entropy',random_state=0, class_weight=\"balanced\")\n",
    "        random_forest.fit(predictorsTreinamento, classesTreinamento)\n",
    "\n",
    "        ax = plt.gca()\n",
    "        rfc_disp = RocCurveDisplay.from_estimator(random_forest, predictorsTeste, classes_teste, ax=ax,alpha=0.9,pos_label=classificacaoPositiva)\n",
    "        major_ticks_x = np.arange(0, 1, 0.1)\n",
    "        major_ticks_y = np.arange(0, 1, 0.05)\n",
    "        minor_ticks = np.arange(0, 1, 0.05)\n",
    "        ax.set_xticks(major_ticks_x)\n",
    "        ax.set_xticks(minor_ticks, minor=True)\n",
    "        ax.set_yticks(major_ticks_y)\n",
    "        ax.set_yticks(minor_ticks, minor=True)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geração dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter(predictions, classificacaoPositiva, classificacaoNegativa):\n",
    "    #Aplica o Filtro de Mediana\n",
    "\n",
    "        return [classificacaoPositiva if x==0 else classificacaoNegativa for x in medfilt(predictions,kernel_size=1)]\n",
    "        # return [classificacaoPositiva if x==1 else classificacaoNegativa for x in medfilt(binary_preditction)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_Results_One_stage(df_results, N, group_name, predictors_treinamento, classes_treinamento_gol, predictors_teste, classes_teste_gol):\n",
    "        start_time = time.time()\n",
    "        predictions = teste(N, predictors_treinamento, classes_treinamento_gol, predictors_teste,0.9)\n",
    "        duration_first_stage = round(time.time() - start_time, 2)\n",
    "        roc_curve_plot(N, predictors_treinamento, classes_treinamento_gol, predictors_teste,classes_teste_gol,'Gol')\n",
    "\n",
    "        predictions_after_filter =  median_filter(predictions, 'Gol', 'Não Gol')\n",
    "\n",
    "        result = confusion_matrix(classes_teste_gol,predictions_after_filter).ravel()\n",
    "\n",
    "        result = np.append(result, duration_first_stage)\n",
    "        result = np.append(accuracy_score(classes_teste_gol, predictions_after_filter), result)\n",
    "        result = np.append(result, N)\n",
    "        result = np.append(result, group_name)\n",
    "        df_result = pd.DataFrame(result).transpose()\n",
    "        df_result.columns = [\"Assertividade Total\", \"Verdadeiro Positivo\",\"Falso Negativo\",\"Falso Positivo\",\"Verdadeiro Negativo\",\"Tempo(s)\", \"N\", \"Grupo\"]\n",
    "        return pd.concat([df_results, df_result], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Second_Stage_Df(features_in_group, predictors_teste, classes_teste_perigo, predictions_perigo_after_filter, classes_teste_gol):\n",
    "        df_predictor_teste = pd.DataFrame(predictors_teste)\n",
    "        df_classes_teste_perigo = pd.DataFrame(classes_teste_perigo)\n",
    "        df_predictions_perigo_after_filter = pd.DataFrame(np.array(predictions_perigo_after_filter))\n",
    "        df_classes_teste_gol = pd.DataFrame(classes_teste_gol)\n",
    "\n",
    "        df_second_stage_intermediary = pd.concat([df_predictor_teste, df_classes_teste_perigo, df_predictions_perigo_after_filter, df_classes_teste_gol], axis=1, ignore_index=True)\n",
    "\n",
    "        column_names = ['Classification_Teste_Perigo', 'Prediction_Teste_Perigo', 'Classification_Gol']\n",
    "        column_names = np.append(features_in_group, column_names)\n",
    "        df_second_stage_intermediary.columns = column_names\n",
    "\n",
    "        #Filtra Apenas os casos que foram classificados Corretamente no primeiro estágio\n",
    "        df_second_stage_intermediary = df_second_stage_intermediary.loc[(df_second_stage_intermediary['Classification_Teste_Perigo'] == df_second_stage_intermediary['Prediction_Teste_Perigo'])]\n",
    "        #Filtra Apenas os casos que foram classificados como Perigo no primeiro estágio\n",
    "        return df_second_stage_intermediary.loc[(df_second_stage_intermediary['Classification_Teste_Perigo'] == 'Perigo')]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Results_Two_Stages(df_results, features_in_group, N, group_name, predictors_treinamento, classes_treinamento_perigo, classes_treinamento_gol, predictors_teste, classes_teste_perigo, classes_teste_gol):\n",
    "        \n",
    "        #######################################Primeiro Estágio####################################\n",
    "        start_time = time.time()\n",
    "        predictions_perigo = teste(N, predictors_treinamento, classes_treinamento_perigo, predictors_teste,0.5)\n",
    "        duration_first_stage = round(time.time() - start_time, 2)\n",
    "        roc_curve_plot(N, predictors_treinamento, classes_treinamento_perigo, predictors_teste,classes_teste_perigo,'Perigo')\n",
    "\n",
    "\n",
    "        predictions_perigo_after_filter =  median_filter(predictions_perigo, 'Perigo', 'Normal')\n",
    "    \n",
    "        result_first_stage = confusion_matrix(classes_teste_perigo, predictions_perigo_after_filter).ravel()\n",
    "        accuracy_first_stage = accuracy_score(classes_teste_perigo, predictions_perigo_after_filter)\n",
    "\n",
    "        result = np.append(accuracy_first_stage, result_first_stage)\n",
    "        result = np.append(result, duration_first_stage)\n",
    "\n",
    "\n",
    "        #######################################Segundo Estágio####################################\n",
    "        df_second_stage = get_Second_Stage_Df(features_in_group, predictors_teste, classes_teste_perigo, predictions_perigo_after_filter, classes_teste_gol)\n",
    "\n",
    "        # Separa Preditores e Classificadores da base de teste\n",
    "        predictors_teste_second_stage = get_predictors(df_second_stage,features_in_group)\n",
    "        classes_teste_gol_second_stage = get_classes_gol(df_second_stage)\n",
    "\n",
    "        start_time = time.time()\n",
    "        predictions_gol = teste(N, predictors_treinamento, classes_treinamento_gol, predictors_teste_second_stage,0.9)\n",
    "        duration_second_stage = round(time.time() - start_time, 2)\n",
    "        roc_curve_plot(N, predictors_treinamento, classes_treinamento_gol, predictors_teste_second_stage,classes_teste_gol_second_stage,'Gol')\n",
    "        \n",
    "\n",
    "        predictions_gol_after_filter =  median_filter(predictions_gol, 'Gol', 'Não Gol')\n",
    "        \n",
    "        accuracy_second_stage = accuracy_score(classes_teste_gol_second_stage, predictions_gol_after_filter)\n",
    "        result_second_stage = confusion_matrix(classes_teste_gol_second_stage, predictions_gol_after_filter).ravel()\n",
    "\n",
    "        result = np.append(result, accuracy_second_stage)\n",
    "        result = np.append(result, result_second_stage)\n",
    "        result = np.append(result, duration_second_stage)\n",
    "\n",
    "        ######################################Resultados Dois Estágios ##########################\n",
    "\n",
    "        result = np.append(result, N)\n",
    "        result = np.append(result, group_name)\n",
    "        df_result = pd.DataFrame(result).transpose()\n",
    "        column_names = [\"Assertividade Total - Primeiro Estagio\", \"Verdadeiro Negativo - Primeiro Estagio\",\"Falso Positivo - Primeiro Estagio\", \"Falso Negativo - Primeiro Estagio\", \"Verdadeiro Positivo - Primeiro Estagio\",\"Tempo(s) - Primeiro Estagio\",\"Assertividade Total - Segundo Estagio\", \"Verdadeiro Positivo - Segundo Estagio\",\"Falso Negativo - Segundo Estagio\",\"Falso Positivo - Segundo Estagio\",\"Verdadeiro Negativo - Segundo Estagio\",\"Tempo(s) - Segundo Estagio\", \"N\", \"Grupo\"]\n",
    "        df_result.columns = column_names\n",
    "        return pd.concat([df_results, df_result], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Results(features_in_group, group_name, moments_treinamento, moments_test):\n",
    "    ############################################################################################\n",
    "\n",
    "    # Separa Preditores e Classificadores da base de treinamento\n",
    "    predictors_treinamento = get_predictors(moments_treinamento, features_in_group)\n",
    "    classes_treinamento_perigo = get_classes_perigo(moments_treinamento)\n",
    "    classes_treinamento_gol = get_classes_gol(moments_treinamento)\n",
    "\n",
    "    # Separa Preditores e Classificadores da base de teste\n",
    "    predictors_teste = get_predictors(moments_test,features_in_group)\n",
    "    classes_teste_perigo = get_classes_perigo(moments_test)\n",
    "    classes_teste_gol = get_classes_gol(moments_test)\n",
    "\n",
    "    # print('Primeiro Estágio')\n",
    "    # Verifica_Importancia(predictors_treinamento, classes_treinamento_perigo)\n",
    "    # print('Segundo Estágio')\n",
    "    # Verifica_Importancia(predictors_treinamento, classes_treinamento_gol)\n",
    "\n",
    " \n",
    "\n",
    "    df_results_one_stage = pd.DataFrame()\n",
    "    df_results_two_stages = pd.DataFrame()\n",
    "    # for N in range(1,101,3):\n",
    "    for N in range(40,41):\n",
    "\n",
    "\n",
    "        print('Valor de N: %d ' % (N))\n",
    "        # df_results_one_stage = get_Results_One_stage(df_results_one_stage, N, group_name, predictors_treinamento, classes_treinamento_gol, predictors_teste, classes_teste_gol)\n",
    "        df_results_two_stages = get_Results_Two_Stages(df_results_two_stages, features_in_group, N, group_name, predictors_treinamento, classes_treinamento_perigo, classes_treinamento_gol, predictors_teste, classes_teste_perigo, classes_teste_gol)\n",
    "\n",
    "\n",
    "    # df_results_one_stage = df_results_one_stage[[\"Assertividade Total\", \"Verdadeiro Positivo\",\"Verdadeiro Negativo\",\"Falso Positivo\",\"Falso Negativo\",\"Tempo(s)\",  \"N\", \"Grupo\"]]\n",
    "    df_results_two_stages = df_results_two_stages[[\"Assertividade Total - Primeiro Estagio\", \"Verdadeiro Positivo - Primeiro Estagio\",\"Verdadeiro Negativo - Primeiro Estagio\",\"Falso Positivo - Primeiro Estagio\",\"Falso Negativo - Primeiro Estagio\",\"Tempo(s) - Primeiro Estagio\",\"Assertividade Total - Segundo Estagio\", \"Verdadeiro Positivo - Segundo Estagio\",\"Verdadeiro Negativo - Segundo Estagio\",\"Falso Positivo - Segundo Estagio\",\"Falso Negativo - Segundo Estagio\",\"Tempo(s) - Segundo Estagio\", \"N\", \"Grupo\"]]\n",
    "    return [df_results_one_stage, df_results_two_stages]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grupo1\n",
      "Valor de N: 40 \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [22831, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12880/3500516034.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m####################################### GERAR CSV DE RESULTADOS de Perigo ################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[1;33m[\u001b[0m\u001b[0mgroup_result_one_stage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_result_two_stages\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_Results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_in_group\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_moments_treinamento\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_moments_teste\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m# final_result_one_stage = pd.concat([final_result_one_stage, group_result_one_stage], axis=0, ignore_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12880/2892307484.py\u001b[0m in \u001b[0;36mget_Results\u001b[1;34m(features_in_group, group_name, moments_treinamento, moments_test)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Valor de N: %d '\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# df_results_one_stage = get_Results_One_stage(df_results_one_stage, N, group_name, predictors_treinamento, classes_treinamento_gol, predictors_teste, classes_teste_gol)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mdf_results_two_stages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_Results_Two_Stages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_results_two_stages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_in_group\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictors_treinamento\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses_treinamento_perigo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses_treinamento_gol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictors_teste\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses_teste_perigo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses_teste_gol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12880/358896255.py\u001b[0m in \u001b[0;36mget_Results_Two_Stages\u001b[1;34m(df_results, features_in_group, N, group_name, predictors_treinamento, classes_treinamento_perigo, classes_treinamento_gol, predictors_teste, classes_teste_perigo, classes_teste_gol)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# predictions_perigo_after_filter = predictions_perigo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mresult_first_stage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses_teste_perigo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions_perigo_after_filter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0maccuracy_first_stage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses_teste_perigo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions_perigo_after_filter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \"\"\"\n\u001b[1;32m--> 302\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    332\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [22831, 1]"
     ]
    }
   ],
   "source": [
    "# Configurações Gerais de Treinamento\n",
    "set_config_treinamento = set_config_treinamento()\n",
    "\n",
    "# Configurações Gerais de Teste\n",
    "set_config_teste = set_config_teste()\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "# # Importa a base de dados\n",
    "# all_moments_treinamento = pd.DataFrame()\n",
    "# all_moments_treinamento = import_database(set_config_treinamento)\n",
    "\n",
    "# # Importa a base de dados\n",
    "# all_moments_teste = pd.DataFrame()\n",
    "# all_moments_teste = import_database(set_config_teste)\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "# Caminhos dos Arquivos de Grupo de Atributo\n",
    "feature_group_paths = set_feature_group_paths()\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "\n",
    "final_result_one_stage = pd.DataFrame()\n",
    "final_result_two_stage = pd.DataFrame()\n",
    "for feature_group_path in feature_group_paths:\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    group_name = feature_group_path.split('\\\\')[-1].replace(\".dat\", \"\")\n",
    "    print(group_name)\n",
    "    \n",
    "    features_in_group = loadtxt(feature_group_path, comments=\"#\", delimiter='\\n', dtype=str, ndmin=1)\n",
    "    \n",
    "####################################### GERAR CSV DE RESULTADOS de Perigo ################################\n",
    "\n",
    "    [group_result_one_stage, group_result_two_stages] = get_Results(features_in_group, group_name, all_moments_treinamento, all_moments_teste)\n",
    "\n",
    "    # final_result_one_stage = pd.concat([final_result_one_stage, group_result_one_stage], axis=0, ignore_index=True)\n",
    "    final_result_two_stage = pd.concat([final_result_two_stage, group_result_two_stages], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "# final_result_one_stage.to_csv( \"..\\\\..\\\\Resultados Modelo\\\\RESULTADO-FINAL-UM-ESTAGIO-v2-Entropia.csv\", index=False, sep=';')\n",
    "final_result_two_stage.to_csv( \"..\\\\..\\\\Resultados Modelo\\\\RESULTADO-FINAL-DOIS-ESTAGIOS-v2-Entropia.csv\", index=False, sep=';', decimal=',',float_format='%.3f')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_result_one_stage.to_csv( \"..\\\\..\\\\Resultados Modelo\\\\RESULTADO-FINAL-UM-ESTAGIO.csv\", index=False, sep=';')\n",
    "# final_result_two_stage.to_csv( \"..\\\\..\\\\Resultados Modelo\\\\RESULTADO-FINAL-DOIS-ESTAGIOS.csv\", index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análises Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Verifica_Importancia(predictors_treinamento, classes_treinamento):\n",
    "\n",
    "    ##############Verificar importancia das features######################\n",
    "    from cProfile import label\n",
    "\n",
    "\n",
    "    random_forest = RandomForestClassifier(n_estimators=100,criterion='entropy',random_state=0)\n",
    "    random_forest.fit(predictors_treinamento, classes_treinamento)\n",
    "\n",
    "    importances = random_forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in random_forest.estimators_], axis=0)\n",
    "\n",
    "    forest_importances = pd.Series(importances, index= ['Atributo 1','Atributo 2','Atributo 3','Atributo 4','Atributo 5','Atributo 6','Atributo 7','Atributo 8','Atributo 9','Atributo 10','Atributo 11','Atributo 12','Atributo 13','Atributo 14','Atributo 15','Atributo 16','Atributo 17','Atributo 18','Atributo 19'])\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "    ax.set_title(\"Importâncias dos Atributos usando MDI\")\n",
    "    ax.set_ylabel(\"Redução Média de Impureza (MDI)\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Verifica_Importancia(predictors_treinamento, classes_treinamento_perigo, classes_treinamento_gol):\n",
    "\n",
    "#     ##############Verificar importancia das features Primeiro Estágio ######################\n",
    "#     from cProfile import label\n",
    "\n",
    "\n",
    "#     random_forest_first_stage = RandomForestClassifier(n_estimators=100,criterion='gini',random_state=0)\n",
    "#     random_forest_first_stage.fit(predictors_treinamento, classes_treinamento_perigo)\n",
    "\n",
    "#     importances_first_stage = random_forest_first_stage.feature_importances_\n",
    "#     std_first_stage = np.std([tree.feature_importances_ for tree in random_forest_first_stage.estimators_], axis=0)\n",
    "\n",
    "#     forest_importances_first_stage = pd.Series(importances_first_stage, index= ['Atributo 1','Atributo 2','Atributo 3','Atributo 4','Atributo 5','Atributo 6','Atributo 7','Atributo 8','Atributo 9','Atributo 10','Atributo 11','Atributo 12','Atributo 13','Atributo 14','Atributo 15','Atributo 16','Atributo 17','Atributo 18','Atributo 19'])\n",
    "\n",
    "\n",
    "#     fig, ax = plt.subplots()\n",
    "#     forest_importances_first_stage.plot.bar(yerr=std_first_stage, ax=ax)\n",
    "#     ax.set_title(\"Importâncias dos Atributos Primeiro Estágio usando MDI\")\n",
    "#     ax.set_ylabel(\"Redução Média de Impureza (MDI)\")\n",
    "#     fig.tight_layout()\n",
    "\n",
    "\n",
    "#     ##############Verificar importancia das features Segundo Estágio ######################\n",
    "#     from cProfile import label\n",
    "\n",
    "\n",
    "#     random_forest_second_stage = RandomForestClassifier(n_estimators=100,criterion='gini',random_state=0)\n",
    "#     random_forest_second_stage.fit(predictors_treinamento, classes_treinamento_gol)\n",
    "\n",
    "#     importances_second_stage = random_forest_second_stage.feature_importances_\n",
    "#     std_second_stage = np.std([tree.feature_importances_ for tree in random_forest_second_stage.estimators_], axis=0)\n",
    "\n",
    "#     forest_importances_second_stage = pd.Series(importances_second_stage, index= ['Atributo 1','Atributo 2','Atributo 3','Atributo 4','Atributo 5','Atributo 6','Atributo 7','Atributo 8','Atributo 9','Atributo 10','Atributo 11','Atributo 12','Atributo 13','Atributo 14','Atributo 15','Atributo 16','Atributo 17','Atributo 18','Atributo 19'])\n",
    "\n",
    "\n",
    "#     fig, ax = plt.subplots()\n",
    "#     forest_importances_second_stage.plot.bar(yerr=std_second_stage, ax=ax)\n",
    "#     ax.set_title(\"Importâncias dos Atributos Segundo Estágio usando MDI\")\n",
    "#     ax.set_ylabel(\"Redução Média de Impureza (MDI)\")\n",
    "#     fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Configurações Gerais de Treinamento\n",
    "# set_config_treinamento = set_config_Aux()\n",
    "\n",
    "# all_moments = import_database(set_config_treinamento)\n",
    "# sns.set(rc={'figure.figsize':(10.2,8.27)})\n",
    "# fig = sns.countplot(y=\"Classification\", hue=\"Match\", data = all_moments, palette=\"tab10\")\n",
    "\n",
    "# fig.set_xlabel(\"Quantidade\")\n",
    "# fig.set_ylabel(\"Classificação\")\n",
    "\n",
    "# plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "# fig = sns.countplot(y=\"Classification\", data = all_moments)\n",
    "# fig.set_xlabel(\"Quantidade\")\n",
    "# fig.set_ylabel(\"Classificação\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52cdd3298a24792fb27a8d65377901584744076590a00194d66ccf79dc821d36"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
