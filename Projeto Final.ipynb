{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final - Análise de Gols em uma Partida de Futebol\n",
    "Autor: Paulo Victor Lima |   Orientador : Sergio Lima Netto |    Universidade Federal do Rio de Janeiro - Escola Politécnica - Departamente de Engenharia Eletrônica e de Computação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instalação das bibliotecas\n",
    "\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install seaborn\n",
    "# !pip install matplotlib.pyplot\n",
    "# !pip install plotly.express\n",
    "# !pip install glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação das bibliotecas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import glob\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import seaborn as sns\n",
    "from numpy import loadtxt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação Base de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classe set_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class set_config():\n",
    "    def __init__(self, match_generic_path, highlights_file_name):\n",
    "\n",
    "        #Carrega as features a serem consideradas\n",
    "        features_types = []\n",
    "        features_types = loadtxt(\"..\\config\\Features_Types.dat\", comments=\"#\", delimiter='\\n', dtype=str, ndmin=1)\n",
    "        self.features_types = features_types\n",
    "\n",
    "        ## Caminho padrão das partidas\n",
    "        self.match_generic_path = match_generic_path\n",
    "\n",
    "        # Nome Padrão arquivo \"Highlights\"\n",
    "        self.highlights_file_name = highlights_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set_config() para treinamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_config_treinamento():\n",
    "    \n",
    "        match_generic_path = '..\\\\database\\\\Treinamento\\\\**\\\\'\n",
    "\n",
    "        highlights_file_name = 'highlights.csv'\n",
    "        \n",
    "        return set_config(match_generic_path, highlights_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set_config() para testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_config_teste():\n",
    "    \n",
    "        match_generic_path = '..\\\\database\\\\Teste\\\\**\\\\'\n",
    "\n",
    "        highlights_file_name = 'highlights.csv'\n",
    "        \n",
    "        return set_config(match_generic_path, highlights_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura Base de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição das Funções de leitura da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_moments_classifictaion(match, len, highlights_file_name):\n",
    "    \n",
    "    #Caminho para os arquivos de features\n",
    "    match_by_feature_path = match + highlights_file_name\n",
    "\n",
    "    #Data frame com todos os intervalos de highligths de uma partida\n",
    "    highlights_file =  pd.DataFrame()\n",
    "\n",
    "    #Data frame com os intervalos de highligths de uma partida\n",
    "    highlights_of_match = pd.DataFrame(list(range(1,len)), columns=['classification'], index=list(range(1,len)))\n",
    "\n",
    "    #nome das colunas do frame de highlights\n",
    "    colnames=['first_frame','last_frame', 'classification'] \n",
    "\n",
    "    #Data Frame com todos os highlights de uma partida\n",
    "    highlights_file = pd.read_csv(match_by_feature_path, names=colnames, index_col=None, sep =',', header=None)\n",
    "\n",
    "    highlights_of_match['classification'] = np.nan\n",
    "    \n",
    "    for index,row in highlights_file.iterrows():        \n",
    "        first_frame = int(row['first_frame']) if int(row['first_frame']) != ' ' else 0\n",
    "        last_frame = int(row['last_frame']) if row['last_frame'] != ' ' else int(row['first_frame'])\n",
    "        classification = row['classification'] if row['classification'] == ' Gol' else 'Não Gol'\n",
    "        highlights_of_match.loc[first_frame:last_frame, 'classification'] = classification\n",
    "        \n",
    "    return highlights_of_match['classification']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_database (set_config):\n",
    "\n",
    "    from numpy import loadtxt\n",
    "\n",
    "    #Carrega as features a serem consideradas\n",
    "    features_types = []\n",
    "    features_types = set_config.features_types\n",
    "\n",
    "    ## Caminho padrão das partidas\n",
    "    match_generic_path = set_config.match_generic_path\n",
    "\n",
    "    #Lista de partidas existentes na base\n",
    "    all_matches = glob.glob(match_generic_path, recursive = False)\n",
    "\n",
    "    ## Data Frame com todos os momementos de todas as partidas\n",
    "    all_moments = pd.DataFrame()\n",
    "    ## Array de Data Frames com todos os Data Frames das partidas\n",
    "    all_moments_array = []\n",
    "\n",
    "    for match in all_matches:\n",
    "        print(match)\n",
    "\n",
    "        #Data frame com todos os momentos de uma partida\n",
    "        moments_of_match=  pd.DataFrame()\n",
    "\n",
    "        for feature in features_types:\n",
    "\n",
    "            #Caminho para os arquivos de features\n",
    "            match_by_feature_path = match + feature\n",
    "\n",
    "            #Data Frame com todos os momentos de uma partida de uma feature especifica\n",
    "            moments_of_match[feature] = pd.read_csv(match_by_feature_path, index_col=None, sep ='\\n', thousands=r\".\", header=None)\n",
    "        \n",
    "        #Preenche a coluna 'Match' com a partida\n",
    "        moments_of_match['Match'] = [match_by_feature_path.split('\\\\')[-2] for _ in range(len(moments_of_match[feature]))]\n",
    "\n",
    "            \n",
    "        moments_of_match['Classification'] = import_moments_classifictaion(match, len(moments_of_match[feature]), set_config.highlights_file_name)\n",
    "\n",
    "        moments_of_match.dropna(axis=0, how='any',inplace=True)\n",
    "\n",
    "        #Adiciona ao array de Data Frames o Data Frame gerado para a partida\n",
    "        all_moments_array.append(moments_of_match)\n",
    "\n",
    "    all_moments = pd.concat(all_moments_array,  sort=False, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "    all_moments.to_csv( set_config.match_generic_path.split('\\\\')[-3] + \"moments.csv\", index=False, sep=';')\n",
    "\n",
    "    return all_moments\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão Previsores e Classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previsores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictors(all_moments):\n",
    "    return all_moments.iloc[:, :-2].values\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(all_moments):\n",
    "    return all_moments.iloc[:, -1:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### TREINAMENTO ##########\n",
    "\n",
    "# Configurações Gerais de Treinamento\n",
    "set_config_treinamento = set_config_treinamento()\n",
    "\n",
    "# Importa a base de dados\n",
    "all_moments_treinamento = pd.DataFrame()\n",
    "all_moments_treinamento = import_database(set_config_treinamento)\n",
    "\n",
    "# Separa Preditores e Classificadores\n",
    "predictors_treinamento = get_predictors(all_moments_treinamento)\n",
    "classes_treinamento = get_classes(all_moments_treinamento)\n",
    "\n",
    "##Cria o Random Forest e realiza o treinamento\n",
    "random_forest = RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)\n",
    "random_forest.fit(predictors_treinamento, classes_treinamento)\n",
    "\n",
    "\n",
    "############ TESTE ##########\n",
    "# Configurações Gerais de Teste\n",
    "set_config_teste = set_config_teste()\n",
    "\n",
    "# Importa a base de dados\n",
    "all_moments_teste = pd.DataFrame()\n",
    "all_moments_teste = import_database(set_config_teste)\n",
    "\n",
    "# Separa Preditores e Classificadores\n",
    "predictors_teste = get_predictors(all_moments_teste)\n",
    "classes_teste = get_classes(all_moments_teste)\n",
    "\n",
    "predictions = random_forest.predict(predictors_teste)\n",
    "\n",
    "############ Verificacao ##########\n",
    "accuracy_score(classes_teste, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pv019\\AppData\\Local\\Temp/ipykernel_19588/3501657085.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  random_forest.fit(predictors_treinamento, classes_treinamento)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.922226821192053"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Cria o Random Forest e realiza o treinamento\n",
    "random_forest = RandomForestClassifier(n_estimators=1000,criterion='entropy',random_state=0)\n",
    "random_forest.fit(predictors_treinamento, classes_treinamento)\n",
    "\n",
    "predictions = random_forest.predict(predictors_teste)\n",
    "\n",
    "############ Verificacao ##########\n",
    "accuracy_score(classes_teste, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análises Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "import_database() missing 1 required positional argument: 'set_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19588/1398781128.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_moments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimport_database\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Classification\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Match\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_moments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: import_database() missing 1 required positional argument: 'set_config'"
     ]
    }
   ],
   "source": [
    "all_moments = import_database()\n",
    "sns.countplot(y=\"Classification\", hue=\"Match\", data = all_moments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.countplot(y=\"Classification\", data = all_moments)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "985cb972b43ba92f3c6e418e6926d7df9365e3002793f34b38da42d3510ab441"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
