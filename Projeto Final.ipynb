{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final - Análise de Gols em uma Partida de Futebol\n",
    "Autor: Paulo Victor Lima |   Orientador : Sergio Lima Netto |    Universidade Federal do Rio de Janeiro - Escola Politécnica - Departamente de Engenharia Eletrônica e de Computação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instalação das bibliotecas\n",
    "\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install seaborn\n",
    "!pip install matplotlib.pyplot\n",
    "!pip install plotly.express\n",
    "!pip install glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação das bibliotecas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import glob\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação Base de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_config():\n",
    "    from numpy import loadtxt\n",
    "\n",
    "    #Carrega as features a serem consideradas\n",
    "    features_types = []\n",
    "    features_types = loadtxt(\"..\\config\\Features_Types.dat\", comments=\"#\", delimiter='\\n', dtype=str, ndmin=1)\n",
    "\n",
    "    ## Caminho padrão das partidas\n",
    "    match_generic_path = '..\\\\database\\\\**\\\\'\n",
    "\n",
    "    # Nome Padrão arquivo \"Highlights\"\n",
    "    highlights_file_name = 'highlights2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição das Funções de leitura da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_moments_classifictaion(match, len):\n",
    "    \n",
    "    # Nome Padrão arquivo \"Highlights\"\n",
    "    highlights_file_name = 'highlights.csv'\n",
    "\n",
    "    #Caminho para os arquivos de features\n",
    "    match_by_feature_path = match + highlights_file_name\n",
    "\n",
    "    #Data frame com todos os intervalos de highligths de uma partida\n",
    "    highlights_file =  pd.DataFrame()\n",
    "\n",
    "    #Data frame com os intervalos de highligths de uma partida\n",
    "    highlights_of_match = pd.DataFrame(list(range(1,len)), columns=['classification'], index=list(range(1,len)))\n",
    "\n",
    "    #nome das colunas do frame de highlights\n",
    "    colnames=['first_frame','last_frame', 'classification'] \n",
    "\n",
    "    #Data Frame com todos os highlights de uma partida\n",
    "    highlights_file = pd.read_csv(match_by_feature_path, names=colnames, index_col=None, sep =',', header=None)\n",
    "\n",
    "    highlights_of_match['classification'] = np.nan\n",
    "    \n",
    "    for index,row in highlights_file.iterrows():        \n",
    "        first_frame = int(row['first_frame']) if int(row['first_frame']) != ' ' else 0\n",
    "        last_frame = int(row['last_frame']) if row['last_frame'] != ' ' else int(row['first_frame'])\n",
    "        classification = row['classification']\n",
    "        highlights_of_match.loc[first_frame:last_frame, 'classification'] = classification\n",
    "        \n",
    "    return highlights_of_match['classification']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_database ():\n",
    "\n",
    "    from numpy import loadtxt\n",
    "\n",
    "    #Carrega as features a serem consideradas\n",
    "    features_types = []\n",
    "    features_types = loadtxt(\"..\\config\\Features_Types.dat\", comments=\"#\", delimiter='\\n', dtype=str, ndmin=1)\n",
    "\n",
    "    ## Caminho padrão das partidas\n",
    "    match_generic_path = '..\\\\database\\\\Treinamento\\\\**\\\\'\n",
    "\n",
    "    #Lista de partidas existentes na base\n",
    "    all_matches = glob.glob(match_generic_path, recursive = False)\n",
    "\n",
    "    ## Data Frame com todos os momementos de todas as partidas\n",
    "    all_moments = pd.DataFrame()\n",
    "    ## Array de Data Frames com todos os Data Frames das partidas\n",
    "    all_moments_array = []\n",
    "\n",
    "    for match in all_matches:\n",
    "        print(match)\n",
    "\n",
    "        #Data frame com todos os momentos de uma partida\n",
    "        moments_of_match=  pd.DataFrame()\n",
    "\n",
    "        for feature in features_types:\n",
    "\n",
    "            #Caminho para os arquivos de features\n",
    "            match_by_feature_path = match + feature\n",
    "\n",
    "            #Data Frame com todos os momentos de uma partida de uma feature especifica\n",
    "            moments_of_match[feature] = pd.read_csv(match_by_feature_path, index_col=None, sep ='\\n', thousands=r\".\", header=None)\n",
    "        \n",
    "        #Preenche a coluna 'Match' com a partida\n",
    "        moments_of_match['Match'] = [match_by_feature_path.split('\\\\')[-2] for _ in range(len(moments_of_match[feature]))]\n",
    "\n",
    "            \n",
    "        moments_of_match['Classification'] = import_moments_classifictaion(match, len(moments_of_match[feature]))\n",
    "\n",
    "        moments_of_match.dropna(axis=0, how='any',inplace=True)\n",
    "\n",
    "        #Adiciona ao array de Data Frames o Data Frame gerado para a partida\n",
    "        all_moments_array.append(moments_of_match)\n",
    "\n",
    "    all_moments = pd.concat(all_moments_array,  sort=False, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "    all_moments.to_csv(\"moments.csv\", index=False, sep=';')\n",
    "\n",
    "    return all_moments\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\database\\Treinamento\\amg_vas\\\n",
      "..\\database\\Treinamento\\arg_ger\\\n",
      "..\\database\\Treinamento\\arg_mex\\\n",
      "..\\database\\Treinamento\\arg_nig\\\n",
      "..\\database\\Treinamento\\arg_sko\\\n",
      "..\\database\\Treinamento\\bar_int\\\n",
      "..\\database\\Treinamento\\bay_int\\\n",
      "..\\database\\Treinamento\\bra_chi\\\n",
      "..\\database\\Treinamento\\bra_ita\\\n",
      "..\\database\\Treinamento\\bra_ned\\\n"
     ]
    }
   ],
   "source": [
    "# Configurações Gerais\n",
    "# set_config()\n",
    "# Importa a base de dados\n",
    "all_moments = pd.DataFrame()\n",
    "\n",
    "all_moments = import_database()\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)\n",
    "random_forest.fit()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "985cb972b43ba92f3c6e418e6926d7df9365e3002793f34b38da42d3510ab441"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
